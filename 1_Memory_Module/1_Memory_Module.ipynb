{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a845c84",
   "metadata": {},
   "source": [
    "# Memory Module\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95638c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain\n",
    "# pip install OpenAI\n",
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9353a",
   "metadata": {},
   "source": [
    "<font color=\"Green\">\n",
    "    <b>Conversational memory :</b>\n",
    "    \n",
    "It helps chatbots to remember past interactions.Conversational memory facilitates this by allowing the agent to recall and utilize information from previous conversations.\n",
    "\n",
    "In summary, conversational memory is essential for chatbots to maintain context, recall past interactions, and engage in more meaningful and coherent conversations with users.\n",
    "    <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4e830f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "import tiktoken\n",
    "\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
    "                                                  ConversationSummaryMemory,\n",
    "                                                  ConversationBufferWindowMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffed36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c394a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = OpenAI(temperature = 0, model_name = \"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05caf2b0",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f5b40",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "    <b>Conversation Buffer Memory</b> helps chatbot to remember our old previous history exactly as it is.\n",
    "   <br> \n",
    "It is allowing the chatbot to refer back to specific parts accurately.\n",
    "     <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52bbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    \n",
    "    llm = llm_model,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ce8035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f118a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Good Morning AI',\n",
       " 'history': '',\n",
       " 'response': \" Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Good Morning AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c8cc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My Name is Sovan\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My Name is Sovan',\n",
       " 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\",\n",
       " 'response': ' Nice to meet you Sovan! What can I do for you today?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My Name is Sovan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d535a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My Name is Sovan\n",
      "AI:  Nice to meet you Sovan! What can I do for you today?\n",
      "Human: I Stay in Kolkata\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I Stay in Kolkata',\n",
       " 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\\nHuman: My Name is Sovan\\nAI:  Nice to meet you Sovan! What can I do for you today?\",\n",
       " 'response': \" Ah, Kolkata! I've heard it's a great city. What do you like most about living there?\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I Stay in Kolkata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2444dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My Name is Sovan\n",
      "AI:  Nice to meet you Sovan! What can I do for you today?\n",
      "Human: I Stay in Kolkata\n",
      "AI:  Ah, Kolkata! I've heard it's a great city. What do you like most about living there?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c255b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My Name is Sovan\n",
      "AI:  Nice to meet you Sovan! What can I do for you today?\n",
      "Human: I Stay in Kolkata\n",
      "AI:  Ah, Kolkata! I've heard it's a great city. What do you like most about living there?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' You said your name is Sovan. Is there something else I can help you with?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb03e36",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ConversationBufferWindowMemory\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e82a45",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "    <b>Conversation Buffer Window Memory</b> helps chatbot to remember our old previous history exactly as it is but it wont store old chat history It only remembers the recent past conversation.\n",
    "   <br> \n",
    "Useful only when you have small memory storgae.\n",
    "     <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a309a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    \n",
    "    llm = llm_model,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=1)\n",
    "    ## k indicates remember past 1 converstion, we can customize it.\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fe9e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Good Morning AI',\n",
       " 'history': '',\n",
       " 'response': \" Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Good Morning AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68fe3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My Name is Sovan\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My Name is Sovan',\n",
       " 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\",\n",
       " 'response': ' Nice to meet you Sovan! What can I do for you today?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My Name is Sovan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2b4a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My Name is Sovan\n",
      "AI:  Nice to meet you Sovan! What can I do for you today?\n",
      "Human: I Stay in Kolkata\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I Stay in Kolkata',\n",
       " 'history': 'Human: My Name is Sovan\\nAI:  Nice to meet you Sovan! What can I do for you today?',\n",
       " 'response': ' Interesting! Kolkata is a beautiful city. What do you like most about it?'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I Stay in Kolkata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f0252bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I Stay in Kolkata\n",
      "AI:  Interesting! Kolkata is a beautiful city. What do you like most about it?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't know your name.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6d74e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is my name?\n",
      "AI:  I'm sorry, I don't know your name.\n"
     ]
    }
   ],
   "source": [
    "# it store only past 1 conversation\n",
    "\n",
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04b05e",
   "metadata": {},
   "source": [
    "---\n",
    "## ConversationSummaryMemory\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6dbcd4",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "    <b>Conversation Summary Memory</b> helps chatbot to remember the summary of our entire chat. when out chat conversation is huge, then this memory module helps llm model to make it as summary. llm also don't feel overloaded. \n",
    "    <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad4f61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    \n",
    "    llm = llm_model,\n",
    "    verbose=True,\n",
    "    memory=ConversationSummaryMemory(llm= llm_model)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4512439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "507a05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66451807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good morning AI!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Good morning! It's a beautiful day today, isn't it? How can I help you?\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Good morning AI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeae65a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greeted the AI with a good morning, to which the AI responded with a good morning and asked how it could help.\n",
      "Human: My Name is Sovan\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Nice to meet you Sovan! How can I help you today?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"My Name is Sovan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8cbaf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The human greeted the AI with a good morning, to which the AI responded with a good morning and asked how it could help. The human introduced themselves as Sovan, to which the AI responded with a friendly greeting.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fca71fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greeted the AI with a good morning, to which the AI responded with a good morning and asked how it could help. The human introduced themselves as Sovan, to which the AI responded with a friendly greeting.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Your name is Sovan. It's nice to meet you. Is there anything else I can help you with?\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0767c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
